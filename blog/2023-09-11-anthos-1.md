---
title: GKE on-prem in Kartverket
description: This is my first post on Docusaurus 2.
slug: gke-on-prem
authors:
  - name: Espen Henriksen
    title: Produkteier SKIP
    url: https://espen.dev
    image_url: https://github.com/esphen.png
tags: [anthos]
image: img/anthos-1.png
hide_table_of_contents: false
---

![](img/anthos-1.png)

Over the years we talked with many other public sector companies about their
experiences in running containers in production. One of the biggest challenges
that we hear again and again is the challenge of running hybridized workloads,
or how to have some workloads running on-premise and some in the the cloud in a
good way. 

In this newsletter we will share some of our experiences with running GKE
on-prem in Kartverket, including the reasons we went with Anthos and pros and
cons we have experienced so far.

<!--truncate-->

In Kartverket we have an ambition to adopt cloud native technologies so that
our developers are more productive and deliver more value. There's thousands of
ways to do this, but after tialing a couple of alternative solutions, including
running plain Kubernetes and VMWare Tanzu, we decided to go with Anthos. Anthos
is a platform that allows us to run Kubernetes clusters on-premise and in the
cloud, and manage them from a single pane of glass. We have been running Anthos
in production for a while now, at least long enough to be able to share our
thoughts.

This newsletter is part of a three-part series newsletter about Anthos in
Kartverket.

1. Why we chose Anthos (You are here!)
2. How we run Anthos (Coming soon)
3. Benefits and what we would have done differently (Coming soon)

## So why a hybrid cloud?

Were you to take the time machine back a few years, you would see Kartverket as a
traditional enterprise with a lot of knowledge and experience in running
on-premise workloads. This knowledge served us well, but also slightly held us
back in terms of our imagination. We knew that there had to be a better way,
but our enterprise was simply not mature enough to adopt a pure cloud strategy.
The fear of the unknown cloud weighed heavily on many people, and therefore few
people wanted to take the risk of moving to the cloud.

This has been something we've worked on for a long time, and still are. After a
long time of working with the stakeholders in the organization, we eventually
built a cloud strategy, which in simple terms stated that we would prefer 
SaaS-products over hosting things ourselves, and that we would move our
workloads to the cloud. 

This cloud strategy, however, came too late for us on SKIP, as we had already
done most of the work on our on-premise platform, building on the assumtions the
organization held at the time. Those assumptions were "cloud is scary" and "we
need to run everything ourselves". So after the cloud strategy emerged it was
full steam ahead, building the on-prem part first, then adding the hybrid and
cloud part later.

It's not like we would have ended up with a pure cloud setup in any case,
though. If you're at all familiar with large enterprises, you will know that
they are often very complex. This is also true for Kartverket, where we have a
lot of legacy systems that are not easy to move to the cloud. We also have a lot
of systems that are not suitable for the cloud, mostly because they are designed
to run in a way that would not be cost effective in the cloud. In addition we
have absolutely massive datasets (petabyte-scale) that would be very expensive
to move to the cloud.

Because of these limitations, a pure cloud strategy is not considered to be a
good fit for us.

A hybrid cloud, however, can give us the scalability and flexibility of the
cloud, while still allowing us to run some of our systems on-prem, with the
experience being more or less seamless for the developers.

## What is Anthos anyway?

Anthos is Google's solution to multicloud. It's a product portfolio where the
main product is GKE (Google Kubernetes Engine) on-premise. Using GKE on-prem
you can run Kubernetes clusters on-premise and manage them from the same
control plane in Google Cloud, as if they were proper cloud clusters.

Fun fact, Anthos is truly multi-cloud. That means you can deploy Anthos
clusters to GKE and on-prem, but also AWS and Azure. On other cloud platforms
it uses the provider's Kubernetes distribution like AKS, but you can still
manage it from GKE anongside your other clusters.

In addition to GKE, the toolbox includes:

### Anthos Service Mesh (ASM)

A networking solution based on Istio. This is sort of the backbone of the
hybrid features of Anthos, as provided you've configured a hybrid mesh it allows
applications deployed to the cloud to communicate with on-premise workloads
automatically and without manual steps like opening firewalls.

### Anthos Config Managment (ACM)

A way to sync git repos into a running cluster. Think GitOps here. Build a repo
containing all your Kubernetes manifests and sync them into your cluster, making
cluster maintinance easier.

ACM also includes a policy controller based on [Open Policy Agent Gatekeeper
(OPA)](https://open-policy-agent.github.io/gatekeeper/website/) which allows
platform developers to build guardrails into developers' workflows using
policies like _"don't allow containers to run as root"_.

### GKE Connect Gateway

The connect gateway allows developers to log on to the cluster using `gcloud`
and `kubectl` commands, despite the cluster potentially being behind a
firewall. From a user experience standpoint this is quite useful, as devs
will be logged in to GCP using two factor authentication, and the same strong
authentication allows you to access kubernetes on-premise.

Connect Gateway also integrates with GCP groups, enabling RBAC in Kubernetes
to be assigned to groups instead of manually administered lists of users.

Currently the connect gateway only supports stateless requests, for example
`kubectl get pods` or `kubectl logs` (including `-f`). It does not support
`port-forward`, `exec` or `run`.

Toolchain same

## Why did we choose it?

## What does Anthos 

There are many reasons why we chose Anthos, but the main reasons are:

- Anthos is to some extent a managed service, which means that cluster 
  maintainance is simplified compared to running plain Kubernetes. 
  This is a huge benefit for us, as we are a small team and don't have the
  resources to do this ourselves.
- Starting a platform team from scratch can be challenging, especially in terms
  of the lack of experience. When starting with Anthos, a lot of best practices
  are baked in to the installation and configuration, which means that we can
  focus on other things.
- Anthos is based on Kubernetes, which means that we can use the same tools and
  workflows for both on-premise and cloud workloads.


