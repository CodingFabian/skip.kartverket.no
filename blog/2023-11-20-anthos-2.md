---
title: Hybrid Kubernetes in production pt. 2
description: >
    In this second installment of the Anthos series, we'll talk about how we run
    Anthos in Kartverket. 
slug: hybrid-kubernetes-in-production-part-2
authors:
  - name: Espen Henriksen
    title: Product Owner and Platform Developer
    url: https://espen.dev
    image_url: https://github.com/esphen.png
  - name: BÃ¥rd Ove Hoel
    title: Tech Lead and Platform Developer
    url: https://github.com/bardove
    image_url: https://github.com/bardove.png
tags: [anthos, kubernetes, hybrid]
image: /img/skip.png
hide_table_of_contents: false
---

![Anthos in Google Cloud](img/anthos-4.jpg)

In this second installment of the Anthos series, we will talk about how we run
Anthos in [Kartverket](https://kartverket.no/en). We'll touch on the hardware,
the software, and the processes we use to keep it running.

By the end we hope that we'll have de-mystified Anthos a bit, and maybe given
you an idea of what it takes to run Anthos in production.

If you haven't read the first part, you can find it
[here](/blog/hybrid-kubernetes-in-production-part-1).

<!--truncate-->

This newsletter is the second of the three part series about Anthos in
Kartverket.

1. [Why we chose Anthos](/blog/hybrid-kubernetes-in-production-part-1)
2. How we run Anthos (You are here!)
3. Benefits and what we would have done differently (Coming soon)

## Installation

Dataplane v2
No Controlplane V2
No Terraform

Updates, what are they like

## GCP integration

IAM / Groups / AIS

GUI screenshots

## Deployment

Deployment is a very interesting subject when it comes to Anthos. As a platform
team, it is our job to make sure that deployment is as quick and convenient as
possible for the product teams. This ambition has led us to iterate on our
processes, which has finally led us to a solution that both we and the
developers enjoy using.

### Iteration 1 - Terraform

When we first started out with Anthos, we had a very manual process for
deploying applications. A service account was provisioned in GCP, which allowed
the developers to impersonate a service account in Kubernetes, which in turn
allowed them to deploy apps using Terraform. This approach worked, but had a
decent amount of rough edges, and also would fail in ways that was hard to
debug.

With this approach the developers would have to manage their own Terraform
files, which most of the time was not within their area of expertise. And while
SKIP was able to build modules and tools to make this easier, it was still a
complex system that was hard to understand. Observability and discoverability
was also an issue.

Because of this we would consistently get feedback that this way of deploying
was too complicated and slow, in addition handling Terraform state was a pain.
As a platform team we're commited to our teams' well being, so we took this
seriously and looked at alternatives. It was around this time we adopted Anthos,
so thus Anthos Config Managment was a natural choice.

### Iteration 2 - Anthos Config Managment (ACM)

![Anthos Config Management architecture showing multiple Git repos deployed to a cluster](img/acm-1.png)

ACM is a set of tools that allows you to declaratively manage your Kubernetes
resources. Here we're mostly going to talk about Config Sync, which is a
[GitOps](https://about.gitlab.com/topics/gitops/) system for Kubernetes.

In a GitOps system, a team will have a Git repository that contains all the
Kubernetes resources that they want to deploy. This repository is then synced
to the Kubernetes cluster, and the resources are applied.

This can be likened to a pull-based system, where the GitOps tool (Config sync)
watches the repo for changes and pulls them into the cluster. This is in
contrast to a push-based system, where a script pushes the changes to a
cluster. It is therefore a dedicated system for deployment to Kubernetes, and
following the [UNIX philosophy](https://en.wikipedia.org/wiki/Unix_philosophy)
which focuses on doing that one thing well.

Using this kind of a workflow solves a lot of the issues around the terraform
based deployment that we had in the previous iteration. No longer do developers
need to set up a complicated integration with GCP service accounts and
impersonation, commiting a file to a Git repo will trigger a deployment. The
Git repo and the manifests in them also works as a state of truth for the
cluster, instead of having to reverse engineer what was deployed based on
terraform diffs and state.

It started well, however we soon ran into issues. The system would often take
a long time to reconcile the sync, and during the sync we would not have any
visibility into what was happening. This was not a deal breaker, but also was
not a particularily good developer experience.

We also ran into issues with self-service. We wanted to give the developers the
ability to provision their own namespaces, but due to the multi-tenant nature
of our clusters, we also had to make sure that the teams were not able to write
to each others' namespaces. This was not a feature we were able to implement,
but luckily our next iteration had this built in, which we'll get back to.

The final nail was the user interface. 


### Final iteration - Argo CD

Argo insead of ACM

## Hybrid Mesh

## Monitoring

Used to use Stackdriver, now using LGTM

## Summary


_Disclaimer - Google, GKE and Anthos are trademarks of Google LLC and this website is not
endorsed by or affiliated with Google in any way._