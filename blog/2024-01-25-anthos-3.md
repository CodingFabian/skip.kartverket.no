---
title: Hybrid Kubernetes in production pt. 3
description: >
    In this final installment of the Anthos series, we'll talk about what we
    learned on the way building hybrid infrastructure
slug: hybrid-kubernetes-in-production-part-3
authors:
  - name: Espen Henriksen
    title: Product Owner and Platform Developer
    url: https://espen.dev
    image_url: https://github.com/esphen.png
tags: [anthos, kubernetes, hybrid]
image: /img/anthos-2.png
hide_table_of_contents: false
---

![Anthos in Google Cloud](img/anthos-4.jpg)

In this final installment of the Anthos series, we will talk about what we
learned on the way to building hybrid infrastructure at [Kartverket](https://kartverket.no/en). 

It's been a long journey, and there's plenty of things we've learned along the
way in building a hybrid Kubernetes platform. We'll try to share some of those
hard earned lessons in this post.

If you haven't read the other parts, you can find the first part
[here](/blog/hybrid-kubernetes-in-production-part-1).

<!--truncate-->

## Do you really need hybrid?

When we started out, there was an assumption that it was simply impossible to
use the cloud. This came from all sides of the organization, and was therefore
taken as a given. SKIP was therefore started as a project to build an on-premise
Kubernetes platform to service our needs as a transition to cloud native
development principles.

As we moved along, a lot of these assumptions were challenged. We found that
most of these assumptions were based on misunderstandings or lack of a deeper
understanding cloud technologies and law. This led to a fear of the unknown, and
subsequently inaction. In the end it turned out that quite a lot of our
workloads indeed could run in public cloud, given some minor adjustments.

Had we started out with the knowledge we have now, we would have probably
started with a public cloud provider, and then moved to hybrid when and if
we saw a need for it. Using a cloud provider's managed Kubernetes offering
is significantly easier than running your own, and you can get started much
quicker and with less risk.

Given our organization, we would probably have ended up with hybrid anyway, but
that complexity could potentially have been moved down the timeline to a point
where the platform was more mature.

Starting with hybrid is a massive undertaking, and you should have a good reason
for doing so. Do you need hybrid, or do you just need to mature your
organization? If you do, reduce the scope of the initial work to get to a
workable platform, and preferably start in the cloud. If you're not sure, you
probably don't need hybrid.

## Hybrid gives your organization flexibility

Now that we've built a platform that seamlessly runs workloads in both public
cloud and on-premise, we have a lot of flexibility in where we run our workloads
and how we manage them. Our experience is that this makes it easier for the
organization to mature legacy workloads.

All our greenfield projects are written with cloud native principles in mind,
which makes it trivial to run them in the cloud. Legacy workloads, however, are
not so lucky. They are often written with a lot of assumptions about the
underlying infrastructure and are not cognizant of the resources they use. This
means they are a poor fit to lift and shift to the cloud, as they will often be
expensive and inefficient.

With a hybrid platform, we can use our on-premise offering as a spring board for
modernization. Product teams will start by shifting their app to our on-premise
Kubernetes platform, and then gradually modernize it to be cloud native. 
This method gives a few immediate benefits from the lift and shift like better
observability, developer experience and security features but also gives fewer of the
drawbacks, as the on-premise cloud is closer to the existing runtime than a
public cloud. Once this is done, smaller chunks kan be rewritten as
microservices and moved to the cloud, communicating with the monolith seamlessly
over the hybrid network. This is sometimes referred to as the [strangler
application](https://microservices.io/patterns/refactoring/strangler-application.html).

This method significantly reduces the scope of refactoring, as one can focus on
gradually rewriting smaller modules instead of rewriting the entire application.

## Abstractions are needed
## Service mesh is hard, but maybe necessary evil to make hybrid less painful

Oh my word how we have struggled with service mesh.

Starting from nothing with a goal of providing a secure-by-default zero-trust
network layer with observability and traffic control is quite the undertaking,
especially when you pair that with setting up a new kubernetes-based
infrastructure from scratch.

How do we feel about Istio? There are various opinions in the team, but if we
average them all out, we're content. It's quite complex and can be hard to
debug, but it does the job. As we've matured and gotten more experience with
Istio, we've also started to see more benefits from it, like extensions for
[handling
OAuth2](https://www.envoyproxy.io/docs/envoy/latest/configuration/http/http_filters/oauth2_filter)
and the traffic control features for gradual rollouts.

## Anthos helps you as a platform team getting started with best practices, even if you plan to move to open source components later
## Autoscaling can be an issue if licenses bill per node
## Plan on using managed services? Check if they are supported on-premise
