{
    "version": "https://jsonfeed.org/version/1",
    "title": "SKIP Blog",
    "home_page_url": "https://skip.kartverket.no/blog",
    "description": "SKIP Blog",
    "items": [
        {
            "id": "https://skip.kartverket.no/blog/crisis-management-exercises",
            "content_html": "<p><img loading=\"lazy\" alt=\"Crisis management exercise\" src=\"https://skip.kartverket.no/assets/images/crisismanagamentexercise-d7535fb5c7f77b781b6d63fafbda2ffe.jpeg\" width=\"1024\" height=\"1024\" class=\"img_ev3q\"></p>\n<p>Every IT organization with some semblance of sanity has at least one crisis management or disaster recovery plan, and probably several, depending on the scope and severity of the scenario.\nRanging from \"one of our more important applications is experiencing issues in production\" through \"everything is on fire\" on to total loss of data,\na good crisis management or disaster recovery plan should help you retain business continuity or at the very least ensure a return to normal operations within the shortest possible timeframe.\nBut when was the last time you actually found the time to test your plans and ability to respond to a crisis?</p>\n<p>And we're not just talking a theoretical abstract exercise - we're talking an actual, realistic scenario involving downtime, troubleshooting, configuration and restoration of services in an actual live environment,\npreferably as close to production in terms of architecture as possible.\nBefore you have had the chance to test every single point of your plans, can you actually be sure that they will work?\nAnd as times change, so do applications, configurations, hardware, architecture - even personnel. New people are added to your team, and people leave - you both need to onboard the new ones and make sure that the knowledge and skillset of people leaving are retained in some fashion.\nHave your plans been updated to take all these factors into account?</p>\n<p>Let us take you on a journey through a couple of SKIPs most recent crisis management exercises and explore what happened,\nhow we handled it and what we learned from it.</p>\n<h2 class=\"anchor anchorWithStickyNavbar_LWe7\" id=\"exercise-1-malicious-actor\">Exercise 1: Malicious actor<a href=\"https://skip.kartverket.no/blog/crisis-management-exercises#exercise-1-malicious-actor\" class=\"hash-link\" aria-label=\"Direct link to Exercise 1: Malicious actor\" title=\"Direct link to Exercise 1: Malicious actor\">​</a></h2>\n<p><img loading=\"lazy\" alt=\"Illustration of malicious actor\" src=\"https://skip.kartverket.no/assets/images/hacker3-a25537fa33206d3caf181c19e2fb9767.jpeg\" width=\"1024\" height=\"1024\" class=\"img_ev3q\"></p>\n<p>The first exercise scenario revolved around a malicious actor gaining privileged access to our production Kubernetes cluster, simulated in this case by our internal sandbox cluster.\nAdmittedly, it was somewhat difficult to set up a realistic scenario without outright disabling some of our security tools,\nso in the end we simulated a hostile takeover of the user account belonging to the person responsible for planning and running the exercise.</p>\n<p>The first sign that something was amiss was an alert from our <a href=\"https://sysdig.com/products/platform/\" target=\"_blank\" rel=\"noopener noreferrer\">Sysdig Secure</a> toolset, a <a href=\"https://falco.org/\" target=\"_blank\" rel=\"noopener noreferrer\">Falco</a>-based agent software which continually monitors our cluster\nfor signs of abnormal activity according to a predefined ruleset and provides a SaaS portal for further analysis and management of threats.\n(We will cover more of our security features and mechanisms and how we try to build a modern kubernetes based application platform with built-in security and zero trust in a future blog post.)\nAfter initial examination, we found that the incident was of such a nature that we engaged our crisis management plan in order to investigate, contain and mitigate the incident.\nWe simulated communication with the organization-level crisis management team, having regular meetings in order to keep them informed of progress.\nSystematic examination of logs and audit logs soon turned up suspicious activity confined to one specific platform developer account, and the\ndecision was made to immediately suspend (simulated in this case) the account, removing all access to organizational systems and in effect locking it out.\nSimultaneously, the malicious software was removed once enough evidence was secured in order to further analyze the actions and impact of it.\nThe exercise was announced as ended once we suspended the compromised user account and removed the malicious application while retaining and analyzing enough logs, forensic captures and other traces of activity.</p>\n<h2 class=\"anchor anchorWithStickyNavbar_LWe7\" id=\"exercise-2-everything-is-on-fire\">Exercise 2: \"Everything is on fire\"<a href=\"https://skip.kartverket.no/blog/crisis-management-exercises#exercise-2-everything-is-on-fire\" class=\"hash-link\" aria-label=\"Direct link to Exercise 2: &quot;Everything is on fire&quot;\" title=\"Direct link to Exercise 2: &quot;Everything is on fire&quot;\">​</a></h2>\n<p><img loading=\"lazy\" alt=\"Illustration of malicious actor\" src=\"https://skip.kartverket.no/assets/images/serverroomonfire-d4f5e0159394923419ba537e82f37102.jpeg\" width=\"1024\" height=\"1024\" class=\"img_ev3q\"></p>\n<p>The second exercise scenario was somewhat more involved, taking place over two days. The incident itself was as follows:\nA software update or rogue script caused catastrophic hardware failure in production infrastructure, necessitating creation of a\nnew Kubernetes cluster from scratch. Once the cluster itself and all underlying infrastructure had been created and configured, it would then be up to our platform team to\ndeploy all necessary IAM configuration, service accounts, RBAC and supporting systems (Istio, ArgoCD ++) needed to deploy workloads and restore normal operations.\nThe exercise itself focused on this second phase of restoration, as the infrastructure configuration and cluster creation itself is done by another team, with little involvement by our platform team members.</p>\n<p>The failure itself was simulated by having our infrastructure team wipe our sandbox environment and present us with a clean-slate Kubernetes cluster.\nWe called an all-hands meeting and set to work restoring services right away. Right at the onset, we recognized that this was a golden opportunity\nboth to ensure that our documentation was up-to-date, consistent and easy to follow, as well as give our three newest team members some much-needed\nexperience and insight into setting up our services from scratch.\nWe therefore decided that the newest team members would be the ones to actually execute all the\nactions outlined in our documentation, while the rest of us followed along and made notes, updated documentation and otherwise provided guidance throughout the process.</p>\n<p>The first run-through of the recovery process took around 2-3 hours before everything was in working order. Keep in mind that we took the time to update our documentation and explain everything we did while we were working, so in a real-life scenario this would have been even quicker. Once the IAM, RBAC, Istio and ArgoCD was up and running, it was merely a matter of using ArgoCD to synchronize and deploy all relevant workloads.\nAfterwards, we had a meeting to discuss the process and what experiences we gained from it. Based on the feedback from this meeting, we made further adjustments and updates to our documentation\nin order to make it even easier to follow on a step-by-step basis, focusing on removing any ambiguity and put any \"tribal\" knowledge among our platform developers into writing.\nThis ensured that we are way less dependent on the knowledge and skillset of specific people, enabling any team member to contribute to recovery efforts by simply following the documentation.</p>\n<p>The newest team members greatly enjoyed being responsible for the recovery effort itself, and expressed a wish to run through the scenario again in order to refine their skills and further improve the documentation.\nTherefore, we decided to set aside most of day 2 to do just that. We had the infrastructure team tear down and setup the cluster again, and let the newest team members loose on it - this time on their own without guidance - an additional two times.\nThe last run-through of the exercise took between 30 and 60 minutes, a significant improvement from the initial attempt.</p>\n<p>All in all, we considered the exercise to be a great success, with many important lessons learned and a substantial improvement in the quality of our documentation and crisis management plans.</p>\n<h2 class=\"anchor anchorWithStickyNavbar_LWe7\" id=\"what-did-we-learn\">What did we learn?<a href=\"https://skip.kartverket.no/blog/crisis-management-exercises#what-did-we-learn\" class=\"hash-link\" aria-label=\"Direct link to What did we learn?\" title=\"Direct link to What did we learn?\">​</a></h2>\n<p><img loading=\"lazy\" alt=\"Illustration of malicious actor\" src=\"https://skip.kartverket.no/assets/images/whatdidwelearn-351c9d63d64164132b84622040fcfa25.jpeg\" width=\"1024\" height=\"1024\" class=\"img_ev3q\"></p>\n<h3 class=\"anchor anchorWithStickyNavbar_LWe7\" id=\"lesson-1-you-are-only-as-good-as-your-documentation\">Lesson 1: You are only as good as your documentation<a href=\"https://skip.kartverket.no/blog/crisis-management-exercises#lesson-1-you-are-only-as-good-as-your-documentation\" class=\"hash-link\" aria-label=\"Direct link to Lesson 1: You are only as good as your documentation\" title=\"Direct link to Lesson 1: You are only as good as your documentation\">​</a></h3>\n<p>Documentation is vitally important during a crisis, and should be detailed enough that any team member may follow it on a step-by-step basis and be able to restore normal service, even with minimal knowledge and during a stressful situation.\nThis ensures that you avoid being dependent upon key personnel that might or might not be available during a crisis scenario, and also ensures that you retain vital institutional knowledge even when team members move on to different tasks or even new jobs.</p>\n<h3 class=\"anchor anchorWithStickyNavbar_LWe7\" id=\"lesson-2-logging-logging-logging-oh-and-monitoring-too\">Lesson 2: Logging, logging, logging! Oh, and monitoring too!<a href=\"https://skip.kartverket.no/blog/crisis-management-exercises#lesson-2-logging-logging-logging-oh-and-monitoring-too\" class=\"hash-link\" aria-label=\"Direct link to Lesson 2: Logging, logging, logging! Oh, and monitoring too!\" title=\"Direct link to Lesson 2: Logging, logging, logging! Oh, and monitoring too!\">​</a></h3>\n<p>Having the ability to search through logs of all parts of our system greatly simplifies any incident management, whether the incident revolved around malicious actors or other factors.\nBut logs by themselves are not sufficient - you need some sort of monitoring and alerting system in order to alert on and react to abnormal situations/behaviour in your systems.\nIdeally, you should be able to react on these alerts instead of messages from users - or worse, customers - that something is wrong.</p>\n<h3 class=\"anchor anchorWithStickyNavbar_LWe7\" id=\"lesson-3-test-your-plans\">Lesson 3: Test your plans!<a href=\"https://skip.kartverket.no/blog/crisis-management-exercises#lesson-3-test-your-plans\" class=\"hash-link\" aria-label=\"Direct link to Lesson 3: Test your plans!\" title=\"Direct link to Lesson 3: Test your plans!\">​</a></h3>\n<p>Merely having plans, routines and documentation is insufficient. Unless they have been thoroughly tested and their quality assured through crisis exercises in realistic scenarios and conditions, they should be treated as flawed and unreliable until the opposite is proven.\nRunning crisis management exercises is a great way to expose flaws, insufficiencies and outdated documentation, and careful note-taking and postmortems should be the norm throughout the exercise in order to easily identify and update weak spots in your plans and documentation. As systems and circumstances change, so should plans and documentation too in order to reflect the new order of the day.</p>\n<h3 class=\"anchor anchorWithStickyNavbar_LWe7\" id=\"lesson-4-communicate\">Lesson 4: Communicate!<a href=\"https://skip.kartverket.no/blog/crisis-management-exercises#lesson-4-communicate\" class=\"hash-link\" aria-label=\"Direct link to Lesson 4: Communicate!\" title=\"Direct link to Lesson 4: Communicate!\">​</a></h3>\n<p>Openness and communication is critical during both exercises and real-world crisis scenarios. Plans should always involve key points of communication - who needs to be informed, whose responsibility it is to keep said people informed, and the frequency, scope and format of information to disseminate.\nThis also applies to communication afterwards. Anyone in your organization should be able to understand what happened, how it was solved and what lessons were learned from it.\nIn Kartverket, we solve this by writing postmortems about incidents, summing up the incident itself and what we learned from it. We favour <a href=\"https://www.atlassian.com/incident-management/postmortem/blameless\" target=\"_blank\" rel=\"noopener noreferrer\">Blameless Postmortems</a>, enabling us to quickly and thoroughly analayze and document all aspects of an incident without focusing on individual mistakes   and avoid passing blame.\nThis contributes to a culture of openness, learning and improvement. Hoarding information and disseminating it only on a \"need-to-know\" basis only breeds distrust and contempt, as does a culture that focuses on blaming and punishing people for mistakes instead of learning from them.\nA further bonus when communicating the happenings and results of your crisis management exercises is the potential to inspire others - when people see the great results and lessons you yourselves have gained from such exercises, they might want to try it with their own systems and teams.</p>\n<h3 class=\"anchor anchorWithStickyNavbar_LWe7\" id=\"lesson-5-let-the-newbies-handle-it\">Lesson 5: Let the \"newbies\" handle it<a href=\"https://skip.kartverket.no/blog/crisis-management-exercises#lesson-5-let-the-newbies-handle-it\" class=\"hash-link\" aria-label=\"Direct link to Lesson 5: Let the &quot;newbies&quot; handle it\" title=\"Direct link to Lesson 5: Let the &quot;newbies&quot; handle it\">​</a></h3>\n<p>Putting our newest team members in charge of the recovery operations was a great learning experience for them, as well as enabling us to quickly find flaws and shortcomings in our documentation and crisis management plans.\nIt is also a great confidence booster, because if they succeed, they'll gain valuable insight and positive experiences with setting up all those scary critical systems from scratch - and if they don't succeed, well, that's not their fault, it was because the documentation and training was insufficent to enable them to handle the situation!</p>\n<h3 class=\"anchor anchorWithStickyNavbar_LWe7\" id=\"lesson-6-crisis-exercises-as-team-building\">Lesson 6: Crisis exercises as team building<a href=\"https://skip.kartverket.no/blog/crisis-management-exercises#lesson-6-crisis-exercises-as-team-building\" class=\"hash-link\" aria-label=\"Direct link to Lesson 6: Crisis exercises as team building\" title=\"Direct link to Lesson 6: Crisis exercises as team building\">​</a></h3>\n<p>Crisis exercises are fun and contribute to better teamwork! They bring everyone together in order to achieve a common goal - get things up and running again as quickly as possible. Combine it with \"pair programming\" - that is, if possible make sure at least two people are working on any given task together - this helps facilitate cooperation and communication, and provides an extra set of eyes to help catch any manual errors or deviations from the plan.</p>\n<h2 class=\"anchor anchorWithStickyNavbar_LWe7\" id=\"thank-you-for-reading\">Thank you for reading!<a href=\"https://skip.kartverket.no/blog/crisis-management-exercises#thank-you-for-reading\" class=\"hash-link\" aria-label=\"Direct link to Thank you for reading!\" title=\"Direct link to Thank you for reading!\">​</a></h2>\n<p>We appreciate you taking the time to read through this blog post. We have learned quite a lot (and had lots of fun) through our approach to crisis management exercises. We hope our experiences and thoughts regarding this subject has been interesting, and that they may inspire others to start doing crisis management exercises as well.</p>",
            "url": "https://skip.kartverket.no/blog/crisis-management-exercises",
            "title": "Crisis Management Exercises",
            "summary": "Crisis management and disaster recovery exercises are a great way to learn and to refine your processes and documentation! You should do it too!\n",
            "date_modified": "2024-02-19T00:00:00.000Z",
            "author": {
                "name": "Thomas Berg",
                "url": "https://github.com/berg-thom"
            },
            "tags": [
                "crisis-management",
                "disaster-recovery",
                "exercises"
            ]
        },
        {
            "id": "https://skip.kartverket.no/blog/hybrid-kubernetes-in-production-part-3",
            "content_html": "<p><img loading=\"lazy\" alt=\"Anthos in Google Cloud\" src=\"https://skip.kartverket.no/assets/images/anthos-6-bf519df28c4acffaa304344b0ad145aa.jpg\" width=\"770\" height=\"588\" class=\"img_ev3q\"></p>\n<p>In this final installment of the Anthos series, we will talk about what we\nlearned on the way to building hybrid infrastructure at <a href=\"https://kartverket.no/en\" target=\"_blank\" rel=\"noopener noreferrer\">Kartverket</a>.</p>\n<p>It's been a long journey, and there's plenty of things we've learned along the\nway in building a hybrid Kubernetes platform. We'll try to share some of those\nhard earned lessons in this post.</p>\n<p>This newsletter is the final entry of a three part series about Anthos in\nKartverket.</p>\n<ol>\n<li><a href=\"https://skip.kartverket.no/blog/hybrid-kubernetes-in-production-part-1\">Why we chose Anthos</a></li>\n<li><a href=\"https://skip.kartverket.no/blog/hybrid-kubernetes-in-production-part-2\">How we run Anthos</a></li>\n<li>Benefits and what we would have done differently (You are here!)</li>\n</ol>\n<h2 class=\"anchor anchorWithStickyNavbar_LWe7\" id=\"do-you-really-need-hybrid\">Do you really need hybrid?<a href=\"https://skip.kartverket.no/blog/hybrid-kubernetes-in-production-part-3#do-you-really-need-hybrid\" class=\"hash-link\" aria-label=\"Direct link to Do you really need hybrid?\" title=\"Direct link to Do you really need hybrid?\">​</a></h2>\n<p>When we started out, there was an assumption that it was simply impossible to\nuse the cloud. This came from all sides of the organization, so this was\ntaken as a given. SKIP was therefore started as a project to build an on-premise\nKubernetes platform to service our needs as a transition to cloud native\ndevelopment principles.</p>\n<p>As we moved along, a lot of these assumptions got challenged. We found that\nmost of these assumptions were based on misunderstandings or a lack of a deeper\nunderstanding of cloud technologies and the surrounding legal aspects. This led\nto a fear of the unknown, and subsequent inaction. In the end it turned out\nthat quite a lot of our workloads could indeed run in the public cloud, given some\nminor adjustments.</p>\n<p>Had we started out with the knowledge we have now, we would probably have\nstarted with a public cloud provider, and then moved to hybrid when and if\nwe saw a need for it. Using a cloud provider's managed Kubernetes offering\nis significantly easier than running your own, and you can get started much\nfaster, with less risk.</p>\n<p>Given our organization, we would probably have ended up with hybrid anyway, but\nthat complexity could potentially have been moved down the timeline to a point\nwhere the platform was more mature.</p>\n<p>Starting with hybrid is a massive undertaking, and you should have a good reason\nfor doing so. Do you need hybrid, or do you just need to mature your\norganization? If you do, reduce the scope of the initial work to get to a\nworkable platform, and preferably start in the cloud, adding hybrid features\nlater. If you're not sure, you probably don't need hybrid.</p>\n<h2 class=\"anchor anchorWithStickyNavbar_LWe7\" id=\"hybrid-gives-your-organization-flexibility\">Hybrid gives your organization flexibility<a href=\"https://skip.kartverket.no/blog/hybrid-kubernetes-in-production-part-3#hybrid-gives-your-organization-flexibility\" class=\"hash-link\" aria-label=\"Direct link to Hybrid gives your organization flexibility\" title=\"Direct link to Hybrid gives your organization flexibility\">​</a></h2>\n<p><img loading=\"lazy\" alt=\"Illustration of cloud components\" src=\"https://skip.kartverket.no/assets/images/cloud-1-92f59291846076655bb737aa95d25a59.jpg\" width=\"2880\" height=\"1200\" class=\"img_ev3q\"></p>\n<p>Now that we've built a platform that seamlessly runs workloads in both public\ncloud and on-premise, we have a lot of flexibility in where we run our workloads\nand how we manage them. Our experience is that this makes it easier for the\norganization to mature legacy workloads.</p>\n<p>All our greenfield projects are written with cloud native principles in mind,\nwhich makes it trivial to run them in the cloud. Legacy workloads, however, are\nnot so lucky. They are often written with a lot of assumptions about the\nunderlying infrastructure and are not cognizant of the resources they use. This\nmeans they are a poor fit to lift and shift to the cloud, as they will often be\nexpensive and inefficient.</p>\n<p>With a hybrid platform, we can use our on-premise offering as a spring board for\nmodernization. Product teams will start by shifting their app to our on-premise\nKubernetes platform, and then gradually modernize it to be cloud native.\nThis method gives a few immediate benefits from the lift and shift like better\nobservability, developer experience and security features but also gives fewer of the\ndrawbacks, as the on-premise cloud is closer to the existing dependencies than a\npublic cloud. Once this is done, smaller chunks kan be rewritten as\nmicroservices and moved to the cloud, communicating with the monolith seamlessly\nover the hybrid network. This is sometimes referred to as the <a href=\"https://microservices.io/patterns/refactoring/strangler-application.html\" target=\"_blank\" rel=\"noopener noreferrer\">strangler\napplication</a>.</p>\n<p>This method significantly reduces the scope of refactoring, as one can focus on\ngradually rewriting smaller modules instead of rewriting the entire application.</p>\n<h2 class=\"anchor anchorWithStickyNavbar_LWe7\" id=\"service-mesh-is-hard-but-maybe-a-necessary-evil-to-make-hybrid-less-painful\">Service mesh is hard, but maybe a necessary evil to make hybrid less painful<a href=\"https://skip.kartverket.no/blog/hybrid-kubernetes-in-production-part-3#service-mesh-is-hard-but-maybe-a-necessary-evil-to-make-hybrid-less-painful\" class=\"hash-link\" aria-label=\"Direct link to Service mesh is hard, but maybe a necessary evil to make hybrid less painful\" title=\"Direct link to Service mesh is hard, but maybe a necessary evil to make hybrid less painful\">​</a></h2>\n<p><img loading=\"lazy\" alt=\"Illustration of service mesh with Istio logo\" src=\"https://skip.kartverket.no/assets/images/mesh-1-154deaa307f1f382bd1b5c33494d1712.png\" width=\"2200\" height=\"917\" class=\"img_ev3q\"></p>\n<p>Oh my word how we have struggled with service mesh.</p>\n<p>Starting from nothing with a goal of providing a secure-by-default zero-trust\nnetwork layer with observability and traffic control is quite an undertaking,\nespecially when you pair that with setting up a new kubernetes-based\ninfrastructure from scratch. Istio is famously complex, and we've had our fair\nshare of that.</p>\n<p>So how do we feel about Istio? There are various opinions in the team, but if we\naverage them all out, we're content. It's quite complex and can be hard to\ndebug, but it does the job. As we've matured and gotten more experience with\nIstio, we've also started to see more benefits, like extensions for <a href=\"https://www.envoyproxy.io/docs/envoy/latest/configuration/http/http_filters/oauth2_filter\" target=\"_blank\" rel=\"noopener noreferrer\">handling\nOAuth2</a>\nand the traffic control features for gradual rollouts which we used for\ncanary-testing the migration of some of our larger applications to SKIP. Not all\nof these features, like EnvoyFilters, are supported by Anthos Service Mesh (ASM),\nwhich is why we're exploring using upstream Istio instead of ASM.</p>\n<p>One thing we quickly learned is to not let the product teams configure the\nservice mesh directly using service mesh resources. This is a recipe for\ndisaster. We tried this in the beginning, and first of all it's a huge\ncomplexity burden for the product teams. We also started getting a lot of\nweird issues when product teams would configure the mesh in ways that broke\ntheir encapsulation. Since the service mesh is a cluster-wide feature, if one\nteam makes an invalid configuration, it can break other teams' workloads.\nKubernetes namespaces be damned. We've therefore moved to a model where the\nplatform team provides an abstraction through\n<a href=\"https://github.dev/kartverket/skiperator\" target=\"_blank\" rel=\"noopener noreferrer\">Skiperator</a> which configures the\nservice mesh on their behalf.</p>\n<p>Finally, I think it's prudent to ask yourself wether or not you actually need a\nservice mesh. If you're running a small cluster with a few services, you'll\nprobably be fine with using the built-in Kubernetes features like Ingress and\nNetwork Policies. The observability features are nice, but you can get most of\nthem with a combination of <a href=\"https://grafana.com/docs/tempo/latest/metrics-generator/service_graphs/\" target=\"_blank\" rel=\"noopener noreferrer\">instrumentation and\nGrafana</a>.</p>\n<p>If you need service mesh then limit the scope until you get comfortable with the\nmesh, for example start with just mTLS and observability, and then add zero\ntrust networking features later.</p>\n<p>Also keep in mind there is a lot of competition in the service mesh space, and\nthere are some interesting alternatives to Istio, like\n<a href=\"https://linkerd.io/\" target=\"_blank\" rel=\"noopener noreferrer\">Linkerd</a> and the up-and-coming <a href=\"https://cilium.io/use-cases/cluster-mesh/\" target=\"_blank\" rel=\"noopener noreferrer\">Cilium Service\nMesh</a>.</p>\n<h2 class=\"anchor anchorWithStickyNavbar_LWe7\" id=\"anthos-helps-you-as-a-platform-team-getting-started-with-best-practices-even-if-you-plan-to-move-to-open-source-components-later\">Anthos helps you as a platform team getting started with best practices.. Even if you plan to move to open source components later<a href=\"https://skip.kartverket.no/blog/hybrid-kubernetes-in-production-part-3#anthos-helps-you-as-a-platform-team-getting-started-with-best-practices-even-if-you-plan-to-move-to-open-source-components-later\" class=\"hash-link\" aria-label=\"Direct link to Anthos helps you as a platform team getting started with best practices.. Even if you plan to move to open source components later\" title=\"Direct link to Anthos helps you as a platform team getting started with best practices.. Even if you plan to move to open source components later\">​</a></h2>\n<p><img loading=\"lazy\" alt=\"Google Anthos logo\" src=\"https://skip.kartverket.no/assets/images/anthos-2-1a3889bc339c3f2ac97e81d32c482cff.png\" width=\"2200\" height=\"917\" class=\"img_ev3q\"></p>\n<p>When our platform team started out a few years ago, we picked some of the\nbrightest cloud engineers from within the organization and combined them with\nsome consultants to work on the platform. Most of these engineers had some\nexperience working with Kubernetes and cloud, but not building something of this\nscale from scratch. The first months would therefore be a learning experience for\nmost of the team.</p>\n<p>I think a lot of teams will be in a similar situation, and this is where a\nmanaged service like Anthos can be a huge help. Anthos is built with best\npractices in mind, so a lot of the architecture decisions were built-in to the\ninstaller. Choosing a managed offering, even when running on-prem has therefore\nhelped us deliver value to the product teams much quicker than if we had to\nbuild everything from scratch.</p>\n<p>What's important to point out is that choosing something that is managed does\nnot rule out using open source components later. We started out using all the\nparts that Anthos gave us, including service mesh, logging, monitoring and\nconfiguration management. Managed services do come with some tradeoffs, however,\nas you lose some of the finer control of the platform. As the team has matured\nand gained experience, we've started to replace some of these components with\nopen source alternatives, which has helped us save money and gain more control\nover our platform. This has the downside of having to maintain these\ncomponents ourselves, but with more experience in the team, this is a tradeoff\nwe feel is worth it.</p>\n<p>Even though we're increasingly using more open source components, we don't\nregret using a paid managed offering in the beginning. It helped us get started\nand make the right decisions early on, and we're now in a position where we can\ncapitalize on that great start.</p>\n<h2 class=\"anchor anchorWithStickyNavbar_LWe7\" id=\"keep-in-mind-autoscaling-when-choosing-licensing-models\">Keep in mind autoscaling when choosing licensing models<a href=\"https://skip.kartverket.no/blog/hybrid-kubernetes-in-production-part-3#keep-in-mind-autoscaling-when-choosing-licensing-models\" class=\"hash-link\" aria-label=\"Direct link to Keep in mind autoscaling when choosing licensing models\" title=\"Direct link to Keep in mind autoscaling when choosing licensing models\">​</a></h2>\n<p><img loading=\"lazy\" alt=\"Autoscaling\" src=\"https://skip.kartverket.no/assets/images/anthos-7-e3f4b6cffc3dd928706042e2610f75e4.png\" width=\"2200\" height=\"917\" class=\"img_ev3q\"></p>\n<p>This may be an obvious point to some of the more experienced platform engineers\nout there, but it was still something that we had to learn. When we started out,\nwe appreciated the simplicity of SaaS products that billed per node, as it made\nit easy to predict costs. We could simply look at the number of nodes we had\nrunning and multiply that with the price per node to get a relatively accurate\nestimate of what this offering would cost. This would turn out to be a double\nedged sword, however.</p>\n<p>It is safe to assume that one of the reasons people choose Kubernetes is the ability\nto scale workloads easily. This could be scaling up to handle more traffic, or\nscaling down to save money. This is a great feature, but as the number of workloads\ngrow, the provisioned nodes will start to become insufficient and new nodes will\nbe provisioned. With Kubernetes and Anthos on VMware this can be done\nautomatically, which is a fantastic feature.</p>\n<p>The problem arises when you scale out more nodes and have a static license that\nbills per node. We've made the mistake of getting contracts with two (now just\none) SaaS providers where we order a set of nodes, let's say 10, and when\nworkloads scale up, we end up with more than 10 nodes. This means we're not\nrunning that SaaS-service's agents on the new nodes, which can be anything from\ninconvenient to critical, depending on the service. In the end we've had to\nrestrict our node scaling to avoid this issue, which goes against the whole\nethos of Kubernetes. We're also provisioning bigger nodes than we need to avoid\nscaling out, which can be suboptimal.</p>\n<p>We're now working with the vendors to get a more flexible license that bills per\nnode on demand, but this is something to keep in mind when choosing a SaaS\noffering. Try to factor in the future scaling needs of your platform when\npurchasing SaaS services.</p>\n<h2 class=\"anchor anchorWithStickyNavbar_LWe7\" id=\"summary\">Summary<a href=\"https://skip.kartverket.no/blog/hybrid-kubernetes-in-production-part-3#summary\" class=\"hash-link\" aria-label=\"Direct link to Summary\" title=\"Direct link to Summary\">​</a></h2>\n<p>To summarize: We've learned a lot on our journey to building a hybrid Kubernetes\nplatform. Over the last few years we've iterated on our platform and learned\nlots of great lessons. It's been a huge help and privilege to have the support\nof our organization, especially in terms of us being allowed to fail and learn\nfrom our mistakes. The Norwegian saying \"it's never too late to turn around\"\ncomes to mind, as we've changed course several times on our journey, sometimes\nto the annoyance of our product teams who depend on a stable platform - but in\nthe end we've ended up with a better product - a platform we can be proud of and\nthat our product teams love using.</p>\n<p>Thanks for reading this series on Anthos and hybrid Kubernetes. We hope you've\nlearned something from our experiences, and that our hard earned lessons can\nhelp you on your journey to building a hybrid Kubernetes platform.</p>\n<p><em>Disclaimer - Google, GKE and Anthos are trademarks of Google LLC and this website is not\nendorsed by or affiliated with Google in any way.</em></p>",
            "url": "https://skip.kartverket.no/blog/hybrid-kubernetes-in-production-part-3",
            "title": "Hybrid Kubernetes in production pt. 3",
            "summary": "In this final installment of the Anthos series, we'll talk about what we learned on the way building hybrid infrastructure\n",
            "date_modified": "2024-01-25T00:00:00.000Z",
            "author": {
                "name": "Espen Henriksen",
                "url": "https://espen.dev"
            },
            "tags": [
                "anthos",
                "kubernetes",
                "hybrid"
            ]
        },
        {
            "id": "https://skip.kartverket.no/blog/skip-on-plattformpodden",
            "content_html": "<p><img loading=\"lazy\" alt=\"Vegar and Espen in the studio\" src=\"https://skip.kartverket.no/assets/images/plattformpodden-5a902026492330eca4b224cab45eb99b.jpg\" width=\"4032\" height=\"2268\" class=\"img_ev3q\"></p>\n<p>Very recently, SKIP was featured on the\n<a href=\"https://plattformpodden.no/\" target=\"_blank\" rel=\"noopener noreferrer\">Plattformpodden</a> podcast! Vegar and Espen were\ninvited to talk about SKIP, how it came to be and what it's like to work on it.</p>\n<p>Give it a listen!</p>\n<p><a href=\"https://plattformpodden.no/episode/6\" target=\"_blank\" rel=\"noopener noreferrer\">https://plattformpodden.no/episode/6</a></p>",
            "url": "https://skip.kartverket.no/blog/skip-on-plattformpodden",
            "title": "SKIP on Plattformpodden!",
            "summary": "SKIP has been featured on the Plattformpodden podcast! Give it a listen!\n",
            "date_modified": "2023-12-26T00:00:00.000Z",
            "author": {
                "name": "Espen Henriksen",
                "url": "https://espen.dev"
            },
            "tags": [
                "podcast",
                "plattformpodden"
            ]
        },
        {
            "id": "https://skip.kartverket.no/blog/hybrid-kubernetes-in-production-part-2",
            "content_html": "<p><img loading=\"lazy\" alt=\"Anthos in Google Cloud\" src=\"https://skip.kartverket.no/assets/images/anthos-4-7d2f18bbcb2f378e0657da61ac28fa2f.jpg\" width=\"2880\" height=\"1200\" class=\"img_ev3q\"></p>\n<p>In this second installment of the Anthos series, we will talk about how we run\nAnthos and hybrid cloud at <a href=\"https://kartverket.no/en\" target=\"_blank\" rel=\"noopener noreferrer\">Kartverket</a>. We'll touch\non the hardware, the software, and the processes we use to keep it running.</p>\n<p>By the end we hope that we'll have de-mystified Anthos a bit, and maybe given\nyou an idea of what it takes to run Anthos in production.</p>\n<p>If you haven't read the first part, you can find it\n<a href=\"https://skip.kartverket.no/blog/hybrid-kubernetes-in-production-part-1\">here</a>.</p>\n<p>This newsletter is the second of the three part series about Anthos in\nKartverket.</p>\n<ol>\n<li><a href=\"https://skip.kartverket.no/blog/hybrid-kubernetes-in-production-part-1\">Why we chose Anthos</a></li>\n<li>How we run Anthos (You are here!)</li>\n<li><a href=\"https://skip.kartverket.no/blog/hybrid-kubernetes-in-production-part-3\">Benefits and what we would have done differently</a></li>\n</ol>\n<h2 class=\"anchor anchorWithStickyNavbar_LWe7\" id=\"installation-and-upgrades\">Installation and upgrades<a href=\"https://skip.kartverket.no/blog/hybrid-kubernetes-in-production-part-2#installation-and-upgrades\" class=\"hash-link\" aria-label=\"Direct link to Installation and upgrades\" title=\"Direct link to Installation and upgrades\">​</a></h2>\n<p><img loading=\"lazy\" alt=\"Illustration of the cluster architecture\" src=\"https://skip.kartverket.no/assets/images/anthos-5-41f824768cab6b841ef2fbdc0f5a375b.png\" width=\"1456\" height=\"1082\" class=\"img_ev3q\"></p>\n<p>We have been early adopters of Anthos, so when doing the install we did not have\noptions for controlplane architecture. We wanted to use existing underlying\nVMware infrastructure, so the nodes in our clusters are VMs, provisioned by\nscripts provided by Google. Our cluster is installed with\n<a href=\"https://kubernetes.io/blog/2017/01/how-we-run-kubernetes-in-kubernetes-kubeception/\" target=\"_blank\" rel=\"noopener noreferrer\">kubeception</a>\ncontrolplane architechture, this no longer the only, or recommended way. The\nrecommended model is <a href=\"https://cloud.google.com/anthos/clusters/docs/on-prem/latest/how-to/create-user-cluster-controlplane-v2\" target=\"_blank\" rel=\"noopener noreferrer\">Controlplane\nV2</a>,\nwhere the controlplane nodes for the user cluster are in the user cluster\nitself.</p>\n<p>In the kubeception model, Kubernetes clusters are nested inside other Kubernetes\nclusters. Specifically, the control plane of the user clusters runs in an\nadmin-cluster. For each on-premise cluster created, a new set of nodes and a\nnamespace are created in the admin cluster.</p>\n<p>To install and make changes to the admin cluster, an admin workstation is\nrequired, which must be located in the same network as the admin cluster. All\nconfigurations are done using a CLI tool called <code>gkectl</code>. This tool handles most\ncluster administration tasks, and the cluster specific configuration is provided\nin YAML files.</p>\n<p>Our cluster setup is more or less static, and most cluster administration tasks\ninvolve upgrading or scaling existing clusters. The SKIP team has a cluster\nreferred to as “sandbox”, which is always the first recipient of potentially\nbreaking changes. After testing in sandbox, we'll deploy changes to both\ndevelopment and test environments, and if nothing breaks, we roll out the\nchanges to our production environment. This is mostly done outside work-hours,\nalthough we have not experienced downtime during cluster upgrades. Here is the\ngeneral workflow for upgrading:</p>\n<ol>\n<li>Upgrade your admin workstation to the target version of your upgrade.</li>\n<li>From your admin workstation, upgrade your user clusters.</li>\n<li>After all of the user clusters have been upgraded, you can upgrade your admin\ncluster from the admin workstation.</li>\n</ol>\n<p>We have tried using <a href=\"https://www.terraform.io/\" target=\"_blank\" rel=\"noopener noreferrer\">Terraform</a> where possible to\nsimplify the setup. This can not be done in the same way for clusters using the\nkubeception model. When we migrate to Controlplane V2 however, clusters can be\nmanaged via GCP, and we can finally start using terraform for our on-premise\ncluster config in the same way as for our GKE clusters, and GCP configuration in\ngeneral.</p>\n<h2 class=\"anchor anchorWithStickyNavbar_LWe7\" id=\"gcp-integration\">GCP integration<a href=\"https://skip.kartverket.no/blog/hybrid-kubernetes-in-production-part-2#gcp-integration\" class=\"hash-link\" aria-label=\"Direct link to GCP integration\" title=\"Direct link to GCP integration\">​</a></h2>\n<p>When working with an on-premise Anthos cluster, some of the nice-to-have\nfeatures of a standard GKE cluster have been lost. However, recently Anthos on\nVMware clusters have gradually received more and more features compared to GKE\nclusters.</p>\n<h3 class=\"anchor anchorWithStickyNavbar_LWe7\" id=\"iam-and-groups\">IAM and Groups<a href=\"https://skip.kartverket.no/blog/hybrid-kubernetes-in-production-part-2#iam-and-groups\" class=\"hash-link\" aria-label=\"Direct link to IAM and Groups\" title=\"Direct link to IAM and Groups\">​</a></h3>\n<p>Since we were early adaptors of Anthos, we had to endure not being able to\ndelegate clusterroles to IAM groups, and had to add single users to\nclusterrole/rolebindings in Kubernetes. This was not a huge problem for us,\nsince we were working with a very limited number of teams and devs, but it was\napparent that this was not going to scale well. Luckily we got support for\ngroups before it was a problem, and our config files went from containing way\ntoo many names and email addresses, to only containing groups.</p>\n<p>Our Google Workspace receives groups and users from our Microsoft Active\nDirectory. Groups are initially created either in Entra ID, or on our local\nDomain Controllers, and at set intervals changes are pushed to Google Workspace.\n<a href=\"https://en.wikipedia.org/wiki/Role-based_access_control\" target=\"_blank\" rel=\"noopener noreferrer\">Role-based access control\n(RBAC)</a> based on\nmembership in these groups was needed. We wanted to manage this through\nTerraform, and created a repo with where we store and configure our entire IAM\nconfiguration. Since we have had growing adoption of Kubernetes and public cloud\nin our organization, more teams, projects and apps have been onboarded to SKIP,\nand this IAM repo has grown. We've tried to simplify the structure more than\nonce, but since this is a problem not affecting dev teams, we have chosen to\nprioritize other tasks.</p>\n<h3 class=\"anchor anchorWithStickyNavbar_LWe7\" id=\"workloads\">Workloads<a href=\"https://skip.kartverket.no/blog/hybrid-kubernetes-in-production-part-2#workloads\" class=\"hash-link\" aria-label=\"Direct link to Workloads\" title=\"Direct link to Workloads\">​</a></h3>\n<p>All clusters created in in Anthos can be viewed from the GCP console, and the\n<a href=\"https://cloud.google.com/anthos/multicluster-management/gateway/using\" target=\"_blank\" rel=\"noopener noreferrer\">Connect\ngateway</a>\nmakes it possible to do management from the console (or via kubectl) as well.\nThe GCP console can be used to get information about, or manage the state of the\ncluster, workloads and resources present. This is a web GUI, part of the GCP\nconsole, and not as snappy as cli-tools, but still usable, and intuitive to use.</p>\n<p><img loading=\"lazy\" alt=\"Anthos in Google Cloud\" src=\"https://skip.kartverket.no/assets/images/workload-5cb93c6dd1fc37775e7194682731de53.png\" width=\"1223\" height=\"618\" class=\"img_ev3q\">\nThis view shows workloads running in the argocd namespace. All workloads\ndisplayed here can be clicked, and explored further.</p>\n<p>When accessing the cluster via the Connect gateway there are some limits. The\nConnect gateway does not handle persistent connections, and this makes it\nimpossible to do <a href=\"https://cloud.google.com/anthos/multicluster-management/gateway/using#run_commands_against_the_cluster\" target=\"_blank\" rel=\"noopener noreferrer\">exec, port-forward, proxy or\nattach</a>.\nThis is not a problem for a production environment, where containers should\nnever be used in this way. But for a dev, or sandbox environment, this is a bit\nof a pain-point.</p>\n<p>This issue should be partially fixed in Kubernetes 1.29 and should be completely\nresolved in Kubernetes 1.30.</p>\n<h3 class=\"anchor anchorWithStickyNavbar_LWe7\" id=\"service-mesh\">Service Mesh<a href=\"https://skip.kartverket.no/blog/hybrid-kubernetes-in-production-part-2#service-mesh\" class=\"hash-link\" aria-label=\"Direct link to Service Mesh\" title=\"Direct link to Service Mesh\">​</a></h3>\n<p>A <a href=\"https://istio.io/latest/about/service-mesh/\" target=\"_blank\" rel=\"noopener noreferrer\">Service Mesh</a> in Kubernetes is\nan infrastructure layer that manages communication between services. We are\nusing Anthos Service Mesh (ASM), which is based on <a href=\"https://istio.io/\" target=\"_blank\" rel=\"noopener noreferrer\">Istio</a> and\nnicely integrated with the GCP console. It's easy to get an overview of\nservices, the connection between them, and what services are connected to either\nour internal or external gateways. This can be displayed in a Topology view, or\nif you click on a service, you'll get a more detailed drilldown.</p>\n<p><img loading=\"lazy\" alt=\"Anthos Service Mesh\" src=\"https://skip.kartverket.no/assets/images/services-67dda8848ee239d94d4edfed09900478.png\" width=\"1539\" height=\"935\" class=\"img_ev3q\">\n<em>A snippet of services running in our sandbox cluster.</em></p>\n<p>When we deploy services to our cluster we create almost all Kubernetes and\nservice-mesh resources with our custom operator;\n<a href=\"https://github.com/kartverket/skiperator\" target=\"_blank\" rel=\"noopener noreferrer\">Skiperator</a>. This operator configures\nthe resources to fit our setup, and applies \"best practices\" the easy way. This\nhas been one of the great success stories in SKIP, and Skiperator is in\ncontinuous development.</p>\n<h2 class=\"anchor anchorWithStickyNavbar_LWe7\" id=\"deployment\">Deployment<a href=\"https://skip.kartverket.no/blog/hybrid-kubernetes-in-production-part-2#deployment\" class=\"hash-link\" aria-label=\"Direct link to Deployment\" title=\"Direct link to Deployment\">​</a></h2>\n<p>Deployment is a very interesting subject when it comes to Anthos. As a platform\nteam, it is our job to make sure that deployment is as quick and convenient as\npossible for the product teams. This ambition has led us to iterate on our\nprocesses, which has finally led us to a solution that both we and the\ndevelopers enjoy using.</p>\n<h3 class=\"anchor anchorWithStickyNavbar_LWe7\" id=\"iteration-1---terraform\">Iteration 1 - Terraform<a href=\"https://skip.kartverket.no/blog/hybrid-kubernetes-in-production-part-2#iteration-1---terraform\" class=\"hash-link\" aria-label=\"Direct link to Iteration 1 - Terraform\" title=\"Direct link to Iteration 1 - Terraform\">​</a></h3>\n<p>When we first started out with Anthos, we had a very manual process for\ndeploying applications. A service account was provisioned in GCP, which allowed\nthe developers to impersonate a service account in Kubernetes, which in turn\nallowed them to deploy apps using Terraform. This approach worked, but had a\ndecent amount of rough edges, and also would fail in ways that was hard to\ndebug.</p>\n<p>With this approach the developers would have to manage their own Terraform\nfiles, which most of the time was not within their area of expertise. And while\nSKIP was able to build modules and tools to make this easier, it was still a\ncomplex system that was hard to understand. Observability and discoverability\nwas also an issue.</p>\n<p>Because of this we would consistently get feedback that this way of deploying\nwas too complicated and slow, in addition handling Terraform state was a pain.\nAs a platform team we're committed to our teams' well being, so we took this\nseriously and looked at alternatives. This was around the time we adopted Anthos,\nso thus Anthos Config Managment was a natural choice.</p>\n<h3 class=\"anchor anchorWithStickyNavbar_LWe7\" id=\"iteration-2---anthos-config-managment-acm\">Iteration 2 - Anthos Config Managment (ACM)<a href=\"https://skip.kartverket.no/blog/hybrid-kubernetes-in-production-part-2#iteration-2---anthos-config-managment-acm\" class=\"hash-link\" aria-label=\"Direct link to Iteration 2 - Anthos Config Managment (ACM)\" title=\"Direct link to Iteration 2 - Anthos Config Managment (ACM)\">​</a></h3>\n<p><img loading=\"lazy\" alt=\"Anthos Config Management architecture showing multiple Git repos deployed to a cluster\" src=\"https://skip.kartverket.no/assets/images/acm-1-46a04fbc7dd63ebcae3c08935a5aa51c.png\" width=\"732\" height=\"726\" class=\"img_ev3q\"></p>\n<p>ACM is a set of tools that allows you to declaratively manage your Kubernetes\nresources. Here we're mostly going to talk about Config Sync, which is a\n<a href=\"https://about.gitlab.com/topics/gitops/\" target=\"_blank\" rel=\"noopener noreferrer\">GitOps</a> system for Kubernetes.</p>\n<p>In a GitOps system, a team will have a Git repository that contains all the\nKubernetes resources that they want to deploy. This repository is then synced\nto the Kubernetes cluster, and the resources are applied.</p>\n<p>This can be likened to a pull-based system, where the GitOps tool (Config sync)\nwatches the repo for changes and pulls them into the cluster. This is in\ncontrast to a push-based system, where a script pushes the changes to a\ncluster. It is therefore a dedicated system for deployment to Kubernetes, and\nfollowing the <a href=\"https://en.wikipedia.org/wiki/Unix_philosophy\" target=\"_blank\" rel=\"noopener noreferrer\">UNIX philosophy</a>\nwhich focuses on doing that one thing well.</p>\n<p>Using this type of a workflow solves a lot of the issues around the Terraform\nbased deployment that we had in the previous iteration. No longer do developers\nneed to set up a complicated integration with GCP service accounts and\nimpersonation, committing a file to a Git repo will trigger a deployment. The\nGit repo and the manifests in them also works as a state of truth for the\ncluster, instead of having to reverse engineer what was deployed based on\nterraform diffs and state.</p>\n<p><img loading=\"lazy\" alt=\"ACM UI showing a sync in progress\" src=\"https://skip.kartverket.no/assets/images/acm-2-1a9a222556da2f846d4f64bb1978db27.gif\" width=\"928\" height=\"568\" class=\"img_ev3q\"></p>\n<p>It started well, however we soon ran into issues. The system would often take\na long time to reconcile the sync, and during the sync we would not have any\nvisibility into what was happening. This was not a deal breaker, but at the\nsame time this was not a particularly good developer experience.</p>\n<p>We also ran into issues with implementing a level of self-service that we were\nsatisfied with. We wanted to give the developers the ability to provision their\nown namespaces, but due to the multi-tenant nature of our clusters we also had\nto make sure that teams were not able to write to each others' namespaces.\nThis was not a feature we were able to implement, but luckily our next iteration\nhad this built in, and we'll get back to that.</p>\n<p>The final nail was the user interface. We simply expected more from a deployment\nsystem than what ACM was able to provide. The only view into the deployment was\na long list of resources, which to a developer that is not an expert in\nKubernetes, was not intuitive enough.</p>\n<h3 class=\"anchor anchorWithStickyNavbar_LWe7\" id=\"final-iteration---argo-cd\">Final iteration - Argo CD<a href=\"https://skip.kartverket.no/blog/hybrid-kubernetes-in-production-part-2#final-iteration---argo-cd\" class=\"hash-link\" aria-label=\"Direct link to Final iteration - Argo CD\" title=\"Direct link to Final iteration - Argo CD\">​</a></h3>\n<p><img loading=\"lazy\" src=\"https://skip.kartverket.no/assets/images/argo-1-10ff6f4861d91a7f670f671e2f0ba43d.png\" width=\"2498\" height=\"1229\" class=\"img_ev3q\"></p>\n<p>This finally brought us to our current iteration. We had heard about Argo CD\nbefore, but initially we were hesitant to add another system to our stack.\nAfter ACM had introduced us to GitOps and we looked deeper into Argo CD, it was\nobvious to us that Argo was more mature and would give our developers a better\nuser experience.</p>\n<p>The killer feature here is the UI. Argo CD has an intuitive and user-friendly\nUI that gives the developers a good overview of what is deployed. Whenever\nanything fails, it's immediately obvious which resource is failing, and Argo\nallows you to drill down into the resource to see the details of the failure,\nlogs for deployments, Kubernetes events, etc.</p>\n<p><img loading=\"lazy\" src=\"https://skip.kartverket.no/assets/images/argo-2-61a9fc0299932ae38d232796c8f4f677.png\" width=\"2499\" height=\"1209\" class=\"img_ev3q\"></p>\n<p>The above photo illustrates this well. Here you can see a project with a number\nof <a href=\"https://github.com/kartverket/skiperator\" target=\"_blank\" rel=\"noopener noreferrer\">Skiperator</a> applications. The\ngreen checkmarks indicate that the application is synced and the green heart\nindicates that the application is healthy. A developer can see the underlying\n\"owned\" resources that Skiperator creates (such as a deployment, service, etc),\nand get a look \"behind the curtain\" to see what is actually deployed. This helps\ndebugging and gives the developers a better insight into what is happening\nduring a deployment.</p>\n<p>In terms of multi tenancy, Argo CD has a concept of projects. A project is a\nset of namespaces that a team has access to, and a team can only use Argo to\nsync to namespaces that are part of their project. The namespace allowlist can\nalso include wildcards, which sounds small but this solved our self-service\nissue! With our apps-repo architecture, we would give a team a \"prefix\" (for\nexample <code>seeiendom-</code>), and that team would then be able to deploy to and create\nany namespace that started with that prefix. If they tried to deploy to another\nteam's namespace they would be stopped, as they would not have access to that\nprefix.</p>\n<p>The prefix feature allows product teams to create a new directory in their apps\nrepo, which will then be synced to the cluster and deployed as a new namespace.\nThis is a very simple and intuitive workflow for creating short-lived\ndeployments, for example for pull requests, and it has been very well received\nby the developers.</p>\n<p>The apps-repo architecture will be a blog post itself at some point, so I won't\ngo too much into it.</p>\n<p>And finally, if you're wondering what disaster recovery of an entire cluster\nlooks like with Argo CD, I leave you with the following video at the end.</p>\n<video controls=\"\" width=\"100%\" muted=\"\"><source src=\"/img/argo-3.mov\" type=\"video/mp4\"></video>\n<h2 class=\"anchor anchorWithStickyNavbar_LWe7\" id=\"hybrid-mesh\">Hybrid Mesh<a href=\"https://skip.kartverket.no/blog/hybrid-kubernetes-in-production-part-2#hybrid-mesh\" class=\"hash-link\" aria-label=\"Direct link to Hybrid Mesh\" title=\"Direct link to Hybrid Mesh\">​</a></h2>\n<p>A hybrid mesh service mesh configuration is a setup that allows for service\nnetworking across different environments. For Kartverket this includes a hybrid\ncloud environment. The setup involves several steps, including setting up\ncross-cluster credentials, installing the east-west gateway, enabling endpoint\ndiscovery, and configuring certificate authorities. All clusters in a hybrid\nmesh are registered to the same fleet host project, and istiod in each cluster\nmust be able to communicate with the Kube-API on the opposing clusters.</p>\n<p>ASM is as previously mentioned based on Istio, and after some internal\ndiscussion we decided to experiment with running vanilla upstream Istio in our\nGKE clusters running in GCP. Pairing it with ASM in our on-premise clusters\nworked as expected (after a bit of config), and we are now running upstream\nIstio in GKE, with ASM on-prem in a multi-cluster setup. We also looked into\nusing managed ASM in our GKE cluster, this was hard for us however, due to it\nrequiring firewall openings on-prem for sources we could not predict.</p>\n<p><img loading=\"lazy\" alt=\"Multi-Primary on different networks\" src=\"https://skip.kartverket.no/assets/images/multi-cluster-37ee6eb4218f5c79582ad4738a942ac6.png\" width=\"748\" height=\"555\" class=\"img_ev3q\"></p>\n<p>We have chosen the <a href=\"https://istio.io/latest/docs/setup/install/multicluster/multi-primary_multi-network/\" target=\"_blank\" rel=\"noopener noreferrer\">Multi-Primary on different\nnetworks</a>\nafter reviewing our network topology and configuration. We connect our\non-premise network, with the GCP VPC through a VPN connection (using host and\nservice projects). To have a production ready environment, the VPN connection\nmust be configured with redundancy.</p>\n<p>We're working towards getting this architecture into production, as this will\nenable us to seamlessly use GKE clusters in GCP together with our on-premise\nclusters. The elasticity of cloud infrastructure can be utilized where needed,\nand we can handle communication between services on different clusters much more\nsmoothly. This has been a bit of a journey to configure, but as a learning\nexperience it has been valuable. Being able to address services seamlessly and\ncommunicate with mTLS enabled by default across sites, zones and clusters\nwithout developers having to think about it feels a bit like magic.</p>\n<h2 class=\"anchor anchorWithStickyNavbar_LWe7\" id=\"monitoring\">Monitoring<a href=\"https://skip.kartverket.no/blog/hybrid-kubernetes-in-production-part-2#monitoring\" class=\"hash-link\" aria-label=\"Direct link to Monitoring\" title=\"Direct link to Monitoring\">​</a></h2>\n<h3 class=\"anchor anchorWithStickyNavbar_LWe7\" id=\"google-cloud-monitoring\">Google Cloud Monitoring<a href=\"https://skip.kartverket.no/blog/hybrid-kubernetes-in-production-part-2#google-cloud-monitoring\" class=\"hash-link\" aria-label=\"Direct link to Google Cloud Monitoring\" title=\"Direct link to Google Cloud Monitoring\">​</a></h3>\n<p><img loading=\"lazy\" alt=\"Google Cloud Monitoring dashboard\" src=\"https://skip.kartverket.no/assets/images/gcp-monitoring-1-eb5c94f71f6e0d8c45c6211002c702e5.png\" width=\"2256\" height=\"1108\" class=\"img_ev3q\"></p>\n<p>GKE Enterprise includes an agent that collects metrics from the cluster and sends\nthem to Google Cloud. This is a great feature which makes it relatively easy\nto get started with metrics and monitoring. However, we have decided not to use\nthe agent, and instead use Grafana and LGTM for metrics and monitoring.</p>\n<p>This is mainly due to a couple of challenges:</p>\n<p>The amount of metrics that are collected out of the box and sent to GCP\ncontributes a significant part of our total spend. It's not that we have a lot\nof clusters, but the amount of metrics that are collected out of the box is very\nhigh, and Anthos' default setup didn't give us the control we needed to be able\nto manage it in a good way.</p>\n<p>Note that this was before <a href=\"https://cloud.google.com/managed-prometheus?hl=en\" target=\"_blank\" rel=\"noopener noreferrer\">Managed Service for\nPrometheus</a> was released with\nmore fine grained control over what metrics are collected. It is now the\nrecommended default, which should make metrics collection easier to manage.</p>\n<p>Second, while Google Cloud Monitoring has a few nice dashboards ready for\nAnthos, it feels inconsistent which dashboards work on-premise and which only\nwork in cloud as they are not labeled as such. This is not a big issue, but it's\na bit annoying. The bigger issue is that all the dashboards feel sluggish and\nslow to load. Several of us have used Grafana before, so we're used to a\nsnappy and responsive UI. In our opinion, Google Cloud Monitoring feels clunky\nin comparison.</p>\n<p>So the cost and the user experience were the main reasons we decided to look at\nalternatives to Google Cloud Monitoring. We ended up using Grafana and LGTM,\nwhich we'll talk about next.</p>\n<h3 class=\"anchor anchorWithStickyNavbar_LWe7\" id=\"grafana-with-the-lgtm-stack\">Grafana with the LGTM stack<a href=\"https://skip.kartverket.no/blog/hybrid-kubernetes-in-production-part-2#grafana-with-the-lgtm-stack\" class=\"hash-link\" aria-label=\"Direct link to Grafana with the LGTM stack\" title=\"Direct link to Grafana with the LGTM stack\">​</a></h3>\n<p><img loading=\"lazy\" alt=\"Grafana dashboard with a Kubernetes cluster overview\" src=\"https://skip.kartverket.no/assets/images/grafana-1-aa91144f9105339f1edf0c1ad1aab0b0.png\" width=\"5088\" height=\"3266\" class=\"img_ev3q\"></p>\n<p>When we realized that our needs were not entirely met by Google Cloud Monitoring,\nwe started a project to develop a monitoring stack that would meet our needs.\nSince Grafana is open source and has a large community, we decided to use that\nas our frontend. Our backend is the LGTM stack, which is a set of open source\ntools that are designed to work well together for ingesting, storing and querying\nlogs, traces and metrics.</p>\n<p>What we noticed immediately was that the product teams were much more engaged\nwith this stack than they were with <a href=\"https://cloud.google.com/monitoring/?hl=en\" target=\"_blank\" rel=\"noopener noreferrer\">Google Cloud\nMonitoring</a>. Previously they would\nnot really look at the dashboards, but now they are using them and even creating\ntheir own. This is a huge win for us, as we want the teams to be engaged with\nthe monitoring and observability of their services.</p>\n<p>It definitely helps that most developers on the product teams are familiar with\nGrafana, which makes it easier for them to get started as the learning curve is\nnot as steep.</p>\n<p>There was a discussion about what the backend should be, if we should use\n<a href=\"https://grafana.com/products/cloud/\" target=\"_blank\" rel=\"noopener noreferrer\">Grafana Cloud</a> or host it ourselves. There\nwould be a lot of benefits of using the cloud, as we would not have to maintain\nthe stack or worry about performance or storage. There was, however, a concern\nabout cost and whether or not log files could be shipped to a cloud provider. In\nthe end we decided to host it ourselves, mostly because we didn't have control\nover what quantities of data we're processing. Now that we have a better\nunderstanding of our usage we can use that to calculate our spend, so we're not\nruling out migrating to Grafana Cloud in the future.</p>\n<p>The collection (scraping) of data is done by <a href=\"https://grafana.com/oss/agent/\" target=\"_blank\" rel=\"noopener noreferrer\">Grafana\nAgent</a>, which is an \"all-in-one\" agent that\ncollects metrics, logs and traces. This means a few less moving parts for the\nstack, as we don't have to run both <a href=\"https://prometheus.io/\" target=\"_blank\" rel=\"noopener noreferrer\">Prometheus</a>,\n<a href=\"https://fluentbit.io/\" target=\"_blank\" rel=\"noopener noreferrer\">Fluent Bit</a> and some\n<a href=\"https://opentelemetry.io/\" target=\"_blank\" rel=\"noopener noreferrer\">OpenTelemetry</a> compatible agent for traces. It's a\nrelatively new project, but it's already relative stable and has a lot of\nfeatures. It uses a funky format for configuration called river, which is based\non Hashicorp's HCL. The config enables forming pipelines to process data before\nit's forwarded to Loki, Tempo or Mimir.  It's a bit different, but it works well\nand is easy to understand and configure to our needs.</p>\n<p><img loading=\"lazy\" alt=\"Alerting with Grafana\" src=\"https://skip.kartverket.no/assets/images/grafana-2-849aa5c18bba686f0b10f13a446ff672.png\" width=\"5088\" height=\"3342\" class=\"img_ev3q\"></p>\n<p>Using a system like Grafana also enables us to build an integrated experience\nthat also includes alerting. Using Grafana alerting and OnCall, we configure\nalerts that are sent to the correct team based on the service that is failing.\nThis helps the teams get a better overview of what is happening in their\nservices, and also helps us as a platform team to not have to be involved in\nevery alert that is triggered.</p>\n<p>Overall we're very happy with the LGTM stack, even though it's a fair bit of\nwork to maintain the stack (especially with Istio and other security measures).\nWe're also happy with Grafana, and we're looking forward to seeing what the\nfuture holds for monitoring and observability in Kubernetes.</p>\n<h2 class=\"anchor anchorWithStickyNavbar_LWe7\" id=\"summary\">Summary<a href=\"https://skip.kartverket.no/blog/hybrid-kubernetes-in-production-part-2#summary\" class=\"hash-link\" aria-label=\"Direct link to Summary\" title=\"Direct link to Summary\">​</a></h2>\n<p>To summarize: We like Anthos, and we think it's a great platform for running\nhybrid Kubernetes. As a platform team we look at each feature on a case-by-case\nbasis, with the goal of giving our developers the best possible experience\ninstead of naively trying to use as much as possible of the platform. Because of\nthis we've decided to use Anthos for Kubernetes and service mesh, but not for\nconfig sync and monitoring. This has given us a great platform that we're\nconfident will serve us well for years to come.</p>\n<p>Stay tuned for the third and final part of this series, where we'll talk about\nthe benefits we've seen from Anthos, and what we would have done differently if\nwe were to start over.</p>\n<p><em>Disclaimer - Google, GKE and Anthos are trademarks of Google LLC and this website is not\nendorsed by or affiliated with Google in any way.</em></p>",
            "url": "https://skip.kartverket.no/blog/hybrid-kubernetes-in-production-part-2",
            "title": "Hybrid Kubernetes in production pt. 2",
            "summary": "In this second installment of the Anthos series, we'll talk about how we run Anthos and hybrid cloud in Kartverket. \n",
            "date_modified": "2023-12-14T00:00:00.000Z",
            "author": {
                "name": "Espen Henriksen",
                "url": "https://espen.dev"
            },
            "tags": [
                "anthos",
                "kubernetes",
                "hybrid"
            ]
        },
        {
            "id": "https://skip.kartverket.no/blog/hybrid-kubernetes-in-production-part-1",
            "content_html": "<p><img loading=\"lazy\" alt=\"Anthos in Google Cloud\" src=\"https://skip.kartverket.no/assets/images/anthos-1-7de3d78d58e53af12f241a38a12f68ef.png\" width=\"3618\" height=\"2994\" class=\"img_ev3q\"></p>\n<p>Over the years we talked with many other public sector companies about their\nexperiences in running containers in production. One of the biggest challenges\nthat we hear again and again is the challenge of running hybridized workloads,\nor how to have some workloads running on-premise and some in the the cloud in a\ngood way.</p>\n<p>In this newsletter-series we will share some of our experiences solving this\nissue by running Anthos on VMWare (or GKE on-prem, if you prefer) tied together\nto the cloud in Kartverket using hybrid mesh. We will also discuss the reasons\nwe went with Anthos and pros and cons we have experienced so far.</p>\n<p>At <a href=\"https://www.kartverket.no/en\" target=\"_blank\" rel=\"noopener noreferrer\">Kartverket</a> we have an ambition to adopt cloud\nnative technologies. There's thousands of ways to do this, and after trialing a\ncouple of alternative solutions, including running plain Kubernetes and VMWare\nTanzu, we decided to go with Anthos. Anthos is a platform that allows us to run\nKubernetes clusters on-premise and in the cloud, and manage them from a single\npane of glass. We have been running Anthos in production for a while now, at\nleast long enough to be able to share our thoughts.</p>\n<p>This newsletter is the first of three part series about Anthos in\nKartverket.</p>\n<ol>\n<li>Why we chose Anthos (You are here!)</li>\n<li><a href=\"https://skip.kartverket.no/blog/hybrid-kubernetes-in-production-part-2\">How we run Anthos</a></li>\n<li><a href=\"https://skip.kartverket.no/blog/hybrid-kubernetes-in-production-part-3\">Benefits and what we would have done differently</a></li>\n</ol>\n<h2 class=\"anchor anchorWithStickyNavbar_LWe7\" id=\"so-why-a-hybrid-cloud\">So why a hybrid cloud?<a href=\"https://skip.kartverket.no/blog/hybrid-kubernetes-in-production-part-1#so-why-a-hybrid-cloud\" class=\"hash-link\" aria-label=\"Direct link to So why a hybrid cloud?\" title=\"Direct link to So why a hybrid cloud?\">​</a></h2>\n<p><img loading=\"lazy\" alt=\"Illustration: Anthos runs on GCP, on-premise, other clouds and Edge\" src=\"https://skip.kartverket.no/assets/images/anthos-3-c8c56e8241d54a23f269d181b5d7eb57.png\" width=\"378\" height=\"235\" class=\"img_ev3q\"></p>\n<p>Were you to take the time machine back a few years, you would see Kartverket as a\ntraditional enterprise with a lot of knowledge and experience in running\non-premise workloads. This knowledge served us well, but also slightly held us\nback in terms of our imagination. We knew that there had to be a better way,\nbut our enterprise was simply not mature enough to adopt a pure cloud strategy.\nThe fear of the unknown cloud weighed heavily on many people, and therefore few\npeople wanted to take the risk of moving to the cloud.</p>\n<p>This is something we've worked on for a long time, and still are. After a\nlong time of working with the stakeholders in the organization, we eventually\nbuilt a cloud strategy, which in simple terms stated that we would prefer\nSaaS-products over hosting things ourselves, and that we would gradually move\nour workloads to the cloud.</p>\n<p>This cloud strategy however, which cleared up a lot of blockers, came too late\nfor us on <abbr title=\"Statens Kartverk Infrastructure Platform\">SKIP</abbr>. At\nthat point we had already done most of the work on our on-premise platform,\nbuilding on the assumptions the organization held at the time, which was that we\nmet our needs through existing infrastructure and that using public cloud had\ndisqualifying cost and compliance implications. For SKIP it was therefore full\nsteam ahead, building the on-prem part first, then adding the hybrid and cloud\npart later.</p>\n<p>It's not like we would have ended up with a pure cloud setup in any case,\nthough. If you're at all familiar with large enterprises, you will know that\nthey are often very complex. This is also true for Kartverket, where we have a\nlot of existing systems that are not easy to move to the cloud. We also have a\nlot of systems that are not suitable for the cloud, mostly because they are\ndesigned to run in a way that would not be cost effective in the cloud. In\naddition we have absolutely massive datasets (petabyte-scale) that would be very\nexpensive to move to the cloud.</p>\n<p>Because of these limitations, a pure cloud strategy is not considered to be a\ngood fit for us.</p>\n<p>A hybrid cloud, however, can give us the scalability and flexibility of the\ncloud, while still allowing us to run some of our systems on-prem, with the\nexperience being more or less seamless for the developers.</p>\n<h2 class=\"anchor anchorWithStickyNavbar_LWe7\" id=\"why-we-chose-anthos\">Why we chose Anthos<a href=\"https://skip.kartverket.no/blog/hybrid-kubernetes-in-production-part-1#why-we-chose-anthos\" class=\"hash-link\" aria-label=\"Direct link to Why we chose Anthos\" title=\"Direct link to Why we chose Anthos\">​</a></h2>\n<p>After some disastrous issues with our previous hybrid cloud PoC (that's a whole\nstory in itself) we decided to to look at what alternatives existed on the\nmarket. We considered various options, but eventually decided to run a PoC on\nAnthos. This was based on a series of conditions at the time, to name a few:</p>\n<ul>\n<li>We had a decent pool of knowledge in GCP compared to AWS and Azure at the time</li>\n<li>Some very well established platform teams in the public sector were also using\nGCP, which meant it would be easier to share work and learnings</li>\n<li>Anthos and GCP seemed to offer a good developer experience, which for us as a\nplatform team is of paramount importance</li>\n<li>A provider like Google is well established in the cloud space (especially\nKubernetes), and would have a fully featured, stable and user friendly product</li>\n</ul>\n<p>SKIP ran the Anthos PoC over a few months, initially as an on-prem offering only.\nDrawing on the knowledge of internal network and infrastructure engineers, this\ntook us all the way from provisioning clusters and networking, to iterating on\ntools and docs and finally onboarding an internal product team on the platform.\nOnce we felt we had learned what we could from the PoC, we gathered thoughts\nfrom the product team, infrastructure team and of course the SKIP platform team.</p>\n<p>The results were unanimous. All the participants lauded the GCP user interfaces that\nallowed visibility into running workloads, as well as the new self-service\nfeatures that came with it. Infrastructure engineers complimented the\ninstallation scripts and documentation, which would make it easier to keep the\nclusters up to date.</p>\n<p>Based on the total package we therefore decided to move ahead with Anthos. To\ninfinity and beyond! 🚀</p>\n<h2 class=\"anchor anchorWithStickyNavbar_LWe7\" id=\"what-is-anthos-anyway\">What is Anthos anyway?<a href=\"https://skip.kartverket.no/blog/hybrid-kubernetes-in-production-part-1#what-is-anthos-anyway\" class=\"hash-link\" aria-label=\"Direct link to What is Anthos anyway?\" title=\"Direct link to What is Anthos anyway?\">​</a></h2>\n<p><img loading=\"lazy\" alt=\"Anthos logo\" src=\"https://skip.kartverket.no/assets/images/anthos-2-1a3889bc339c3f2ac97e81d32c482cff.png\" width=\"2200\" height=\"917\" class=\"img_ev3q\"></p>\n<p>Anthos is Google's solution to multicloud. It's a product portfolio where the\nmain product is GKE (Google Kubernetes Engine) on-premise. Using GKE on-prem\nyou can run Kubernetes clusters on-premise and manage them from the same\ncontrol plane in Google Cloud, as if they were proper cloud clusters.</p>\n<p>In fact, Anthos is truly multi-cloud. That means you can deploy Anthos\nclusters to GKE and on-prem, but also AWS and Azure. On other cloud platforms\nit uses the provider's Kubernetes distribution like\n<a href=\"https://learn.microsoft.com/en-us/azure/aks/\" target=\"_blank\" rel=\"noopener noreferrer\">AKS</a>, but you can still manage it\nfrom GKE alongside your other clusters.</p>\n<p>In addition to GKE, the toolbox includes:</p>\n<h3 class=\"anchor anchorWithStickyNavbar_LWe7\" id=\"anthos-service-mesh-asm\">Anthos Service Mesh (ASM)<a href=\"https://skip.kartverket.no/blog/hybrid-kubernetes-in-production-part-1#anthos-service-mesh-asm\" class=\"hash-link\" aria-label=\"Direct link to Anthos Service Mesh (ASM)\" title=\"Direct link to Anthos Service Mesh (ASM)\">​</a></h3>\n<p>A networking solution based on <a href=\"http://istio.io/\" target=\"_blank\" rel=\"noopener noreferrer\">Istio</a>. This is sort of the\nbackbone of the hybrid features of Anthos, as provided you've configured a\nhybrid mesh it allows applications deployed to the cloud to communicate with\non-premise workloads automatically and without manual steps like opening\nfirewalls.</p>\n<p>All traffic that flows between microservices on the mesh is also automatically\nencrypted with mTLS.</p>\n<h3 class=\"anchor anchorWithStickyNavbar_LWe7\" id=\"anthos-config-managment-acm\">Anthos Config Managment (ACM)<a href=\"https://skip.kartverket.no/blog/hybrid-kubernetes-in-production-part-1#anthos-config-managment-acm\" class=\"hash-link\" aria-label=\"Direct link to Anthos Config Managment (ACM)\" title=\"Direct link to Anthos Config Managment (ACM)\">​</a></h3>\n<p>A way to sync git repos into a running cluster. Think GitOps here. Build a repo\ncontaining all your Kubernetes manifests and sync them into your cluster, making\ncluster maintenance easier.</p>\n<p>ACM also includes a policy controller based on <a href=\"https://open-policy-agent.github.io/gatekeeper/website/\" target=\"_blank\" rel=\"noopener noreferrer\">Open Policy Agent Gatekeeper\n(OPA)</a> which allows\nplatform developers to build guardrails into developers' workflows using\npolicies like <em>\"don't allow containers to run as root\"</em>.</p>\n<h3 class=\"anchor anchorWithStickyNavbar_LWe7\" id=\"anthos-connect-gateway\">Anthos Connect Gateway<a href=\"https://skip.kartverket.no/blog/hybrid-kubernetes-in-production-part-1#anthos-connect-gateway\" class=\"hash-link\" aria-label=\"Direct link to Anthos Connect Gateway\" title=\"Direct link to Anthos Connect Gateway\">​</a></h3>\n<p>The connect gateway allows developers to log on to the cluster using <code>gcloud</code>\nand <code>kubectl</code> commands, despite the cluster potentially being behind a\nfirewall. From a user experience standpoint this is quite useful, as devs\nwill be logged in to GCP using two factor authentication, and the same strong\nauthentication allows you to access kubernetes on-premise.</p>\n<p>Connect Gateway also integrates with GCP groups, enabling RBAC in Kubernetes\nto be assigned to groups instead of manually administered lists of users.</p>\n<p>Currently the connect gateway only supports stateless requests, for example\n<code>kubectl get pods</code> or <code>kubectl logs</code> (including <code>-f</code>). It does not support\n<code>port-forward</code>, <code>exec</code> or <code>run</code>, which can be a bit annoying.</p>\n<h2 class=\"anchor anchorWithStickyNavbar_LWe7\" id=\"summary\">Summary<a href=\"https://skip.kartverket.no/blog/hybrid-kubernetes-in-production-part-1#summary\" class=\"hash-link\" aria-label=\"Direct link to Summary\" title=\"Direct link to Summary\">​</a></h2>\n<p>As you can see, the above tools gives us a lot of benefits.</p>\n<ul>\n<li>Combined with the power of Google Cloud and\nTerraform, they give us a good combination of flexibility through cloud services</li>\n<li>Ease the maintenance by using the tools that Anthos and Terraform supply us</li>\n<li>Eases the compliance and modernization burden by allowing a gradual or\npartial migration to cloud, allowing parts to remain on-premise while still\nretaining most of the modern tooling of the cloud</li>\n</ul>\n<p>That's it for now! 🙂 We'll be back with more details on how we run Anthos as\nwell as the pros and cons we've seen so far in the coming weeks. Stay tuned!</p>\n<p><em>Disclaimer - Google, GKE and Anthos are trademarks of Google LLC and this website is not\nendorsed by or affiliated with Google in any way.</em></p>",
            "url": "https://skip.kartverket.no/blog/hybrid-kubernetes-in-production-part-1",
            "title": "Hybrid Kubernetes in production pt. 1",
            "summary": "One of the biggest challenges that we hear is the challenge of running hybridized K8s workloads. Here we share our experience using Anthos for hybrid cloud\n",
            "date_modified": "2023-11-07T00:00:00.000Z",
            "author": {
                "name": "Espen Henriksen",
                "url": "https://espen.dev"
            },
            "tags": [
                "anthos",
                "kubernetes",
                "hybrid"
            ]
        },
        {
            "id": "https://skip.kartverket.no/blog/welcome",
            "content_html": "<p><img loading=\"lazy\" alt=\"Anthos in Google Cloud\" src=\"data:image/png;base64,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\" width=\"250\" height=\"285\" class=\"img_ev3q\"></p>\n<p>SKIP is starting a tech blog! 🚀</p>\n<p>Or call it a newsletter if you're tired of blogs 🤪</p>\n<p>Our first entry is already out, and it's about <a href=\"https://skip.kartverket.no/blog/hybrid-kubernetes-in-production-part-1\">why we chose\nAnthos</a> for hybrid cloud. We're\nworking on more entries into that series and other exciting topics, so stay\ntuned!</p>\n<p>SKIP is Statens Kartverks Infrastruktur Plattform, or in English, the\nInfrastructure Platform of the Norwegian Mapping Authority.</p>\n<p>We're the platform team at <a href=\"https://kartverket.no/\" target=\"_blank\" rel=\"noopener noreferrer\">Kartverket</a>. We tame\nKubernetes and the Cloud. With SKIP, developers in Kartverket are empowered to\nrun, not walk, using a comprehensive toolbox of modern cloud technology. Using\nSKIP, developers can deploy applications to Kubernetes in a matter of minutes,\nwhile still being able to use the tools they know and love.</p>\n<h1>Like what you see?</h1>\n<p>We're a small team, but we're growing fast. We're also hiring, so if you're\ninterested in working with us, check out our <a href=\"https://www.kartverket.no/en/about-kartverket/careers\" target=\"_blank\" rel=\"noopener noreferrer\">open\npositions</a>.</p>",
            "url": "https://skip.kartverket.no/blog/welcome",
            "title": "SKIP has a tech blog!",
            "summary": "SKIP is starting a tech blog! 🚀\n",
            "date_modified": "2023-11-06T00:00:00.000Z",
            "author": {
                "name": "Espen Henriksen",
                "url": "https://espen.dev"
            },
            "tags": []
        }
    ]
}